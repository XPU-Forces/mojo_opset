TTXNorm_TORCH_REF, x: Tensor(shape=(1, 32, 2048), dtype=torch.float32, device=npu:0) | Device latency = 29.3328 us | Host latency = 0.0715 ms
TTXNorm, x: Tensor(shape=(1, 32, 2048), dtype=torch.float32, device=npu:0) | Device latency = 6.6762 us | Host latency = 0.3115 ms
TTXNorm_TORCH_REF, x: Tensor(shape=(1, 32, 2048), dtype=torch.float16, device=npu:0) | Device latency = 36.9086 us | Host latency = 0.0775 ms
TTXNorm, x: Tensor(shape=(1, 32, 2048), dtype=torch.float16, device=npu:0) | Device latency = 5.9242 us | Host latency = 0.2880 ms
TTXNorm_TORCH_REF, x: Tensor(shape=(1, 32, 2048), dtype=torch.bfloat16, device=npu:0) | Device latency = 36.2284 us | Host latency = 0.0993 ms
TTXNorm, x: Tensor(shape=(1, 32, 2048), dtype=torch.bfloat16, device=npu:0) | Device latency = 5.8280 us | Host latency = 0.2917 ms
TTXNorm_TORCH_REF, x: Tensor(shape=(256, 128), dtype=torch.float32, device=npu:0) | Device latency = 79.5338 us | Host latency = 0.1149 ms
TTXNorm, x: Tensor(shape=(256, 128), dtype=torch.float32, device=npu:0) | Device latency = 6.6120 us | Host latency = 0.2783 ms
TTXNorm_TORCH_REF, x: Tensor(shape=(256, 128), dtype=torch.float16, device=npu:0) | Device latency = 68.2084 us | Host latency = 0.1114 ms
TTXNorm, x: Tensor(shape=(256, 128), dtype=torch.float16, device=npu:0) | Device latency = 5.8522 us | Host latency = 0.2622 ms
TTXNorm_TORCH_REF, x: Tensor(shape=(256, 128), dtype=torch.bfloat16, device=npu:0) | Device latency = 67.3936 us | Host latency = 0.1085 ms
TTXNorm, x: Tensor(shape=(256, 128), dtype=torch.bfloat16, device=npu:0) | Device latency = 6.2320 us | Host latency = 0.2612 ms
TTXRoPE_TORCH_REF, k: Tensor(shape=(1, 8, 1024, 32), dtype=torch.float32, device=npu:0), q: Tensor(shape=(1, 32, 1024, 32), dtype=torch.float32, device=npu:0), rope: <TTXRoPE>, sin: Tensor(shape=(1, 1, 1024, 32), dtype=torch.float32, device=npu:0) | Device latency = 315.8940 us | Host latency = 0.2850 ms
TTXRoPE, k: Tensor(shape=(1, 8, 1024, 32), dtype=torch.float32, device=npu:0), q: Tensor(shape=(1, 32, 1024, 32), dtype=torch.float32, device=npu:0), rope: <TTXRoPE>, sin: Tensor(shape=(1, 1, 1024, 32), dtype=torch.float32, device=npu:0) | Device latency = 26.4886 us | Host latency = 0.3302 ms
TTXGelu_TORCH_REF, x: Tensor(shape=(128, 128), dtype=torch.float32, device=npu:0) | Device latency = 1.8920 us | Host latency = 0.0353 ms
TTXGelu, x: Tensor(shape=(128, 128), dtype=torch.float32, device=npu:0) | Device latency = 4.9560 us | Host latency = 0.3020 ms
TTXSilu_TORCH_REF, x: Tensor(shape=(128, 128), dtype=torch.float32, device=npu:0) | Device latency = 1.9480 us | Host latency = 0.0436 ms
TTXSilu, x: Tensor(shape=(128, 128), dtype=torch.float32, device=npu:0) | Device latency = 4.4162 us | Host latency = 0.2886 ms
TTXSwiGLU_TORCH_REF, swiglu: <TTXSwiGLU>, up_out: Tensor(shape=(256, 128), dtype=torch.float32, device=npu:0) | Device latency = 5.0640 us | Host latency = 0.0342 ms
TTXSwiGLU, swiglu: <TTXSwiGLU>, up_out: Tensor(shape=(256, 128), dtype=torch.float32, device=npu:0) | Device latency = 5.1040 us | Host latency = 0.3869 ms
TTXGatedDeltaRule_TORCH_REF, cu_seqlens: Tensor(shape=(3,), dtype=torch.int64, device=npu:0), g: Tensor(shape=(1, 512, 4), dtype=torch.float16, device=npu:0), gated_delta_rule: <TTXGatedDeltaRule>, k: Tensor(shape=(1, 512, 4, 128), dtype=torch.float16, device=npu:0), q: Tensor(shape=(1, 512, 24, 128), dtype=torch.float16, device=npu:0), v: Tensor(shape=(1, 512, 4, 256), dtype=torch.float16, device=npu:0) | Device latency = 16505.1996 us | Host latency = 37.1832 ms
TTXGatedDeltaRule, cu_seqlens: Tensor(shape=(3,), dtype=torch.int64, device=npu:0), g: Tensor(shape=(1, 512, 4), dtype=torch.float16, device=npu:0), gated_delta_rule: <TTXGatedDeltaRule>, k: Tensor(shape=(1, 512, 4, 128), dtype=torch.float16, device=npu:0), q: Tensor(shape=(1, 512, 24, 128), dtype=torch.float16, device=npu:0), v: Tensor(shape=(1, 512, 4, 256), dtype=torch.float16, device=npu:0) | Device latency = 17293.1130 us | Host latency = 10.7195 ms
TTXPagedDecodeGQA_TORCH_REF, k_cache: Tensor(shape=(132, 4, 32, 128), dtype=torch.bfloat16, device=npu:0), paged_attn_decode: <TTXPagedDecodeGQA>, query: Tensor(shape=(8, 16, 128), dtype=torch.bfloat16, device=npu:0), seqlens: Tensor(shape=(8,), dtype=torch.int32, device=npu:0), sm_scale: 0.08838834764831843, v_cache: Tensor(shape=(132, 4, 32, 128), dtype=torch.bfloat16, device=npu:0) | Device latency = 4402.6652 us | Host latency = 10.8775 ms
TTXPagedDecodeGQA, k_cache: Tensor(shape=(132, 4, 32, 128), dtype=torch.bfloat16, device=npu:0), paged_attn_decode: <TTXPagedDecodeGQA>, query: Tensor(shape=(8, 16, 128), dtype=torch.bfloat16, device=npu:0), seqlens: Tensor(shape=(8,), dtype=torch.int32, device=npu:0), sm_scale: 0.08838834764831843, v_cache: Tensor(shape=(132, 4, 32, 128), dtype=torch.bfloat16, device=npu:0) | Device latency = 96.4738 us | Host latency = 0.3655 ms
TTXPagedPrefillGQA_TORCH_REF, cu_seqlens_q: Tensor(shape=(3,), dtype=torch.int64, device=npu:0), k_cache: Tensor(shape=(58, 4, 32, 128), dtype=torch.bfloat16, device=npu:0), paged_attn_prefill: <TTXPagedPrefillGQA>, query: Tensor(shape=(1504, 16, 128), dtype=torch.bfloat16, device=npu:0), sm_scale: 0.08838834764831843, v_cache: Tensor(shape=(58, 4, 32, 128), dtype=torch.bfloat16, device=npu:0) | Device latency = 3516.1788 us | Host latency = 6.2900 ms
TTXPagedPrefillGQA, cu_seqlens_q: Tensor(shape=(3,), dtype=torch.int64, device=npu:0), k_cache: Tensor(shape=(58, 4, 32, 128), dtype=torch.bfloat16, device=npu:0), paged_attn_prefill: <TTXPagedPrefillGQA>, query: Tensor(shape=(1504, 16, 128), dtype=torch.bfloat16, device=npu:0), sm_scale: 0.08838834764831843, v_cache: Tensor(shape=(58, 4, 32, 128), dtype=torch.bfloat16, device=npu:0) | Device latency = 15899.3776 us | Host latency = 16.5120 ms
